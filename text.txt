1 - "DQN_Model2.pth":
    Model: L1 = 128, L2 = 64
    Training: epochs = 200000, C = 200, batch size = 64, learning rate = 0.001, gamma = 0.99
    epsilon greedy: epsilon_start = 1, epsilon_final = 0.01, epsilon_decay = 5000
    *bug in rewards => didn't train well

2: "DQN_Model5.pth":
    Model: L1 = 128, L2 = 64
    Training: epochs = 200000, C = 200, batch size = 64, learning rate = 0.001, gamma = 0.99
    epsilon greedy: epsilon_start = 1, epsilon_final = 0.01, epsilon_decay = 5000
    *bug in trainer => didn't train well

3: "DQN_Model6.pth":
    Model: L1 = 128, L2 = 64
    Training: epochs = 300000, C = 200, batch size = 64, learning rate = 0.001, gamma = 0.99
    epsilon greedy: epsilon_start = 1, epsilon_final = 0.01, epsilon_decay = 5000
    *bug in trainer => didn't train well

4: "DQN_Model7.pth":
    Model: L1 = 128, L2 = 64
    Training: epochs = 300000, C = 200, batch size = 64, learning rate = 0.001, gamma = 0.99
    epsilon greedy: epsilon_start = 1, epsilon_final = 0.01, epsilon_decay = 5000
    *bug in trainer => didn't train well

5: "DQN_Model8.pth":
    Model: L1 = 128, L2 = 64
    Training: epochs = 50000, C = 200, batch size = 64, learning rate = 0.001, gamma = 0.99
    epsilon greedy: epsilon_start = 1, epsilon_final = 0.01, epsilon_decay = 5000
    *TODO: find problem
    

